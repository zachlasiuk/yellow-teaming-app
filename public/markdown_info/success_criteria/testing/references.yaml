references:
  - name: "US NIST Framework"
    type: "Law"
    sections:     
      - section: "MEA 2.3"
        title: "Testing in deployment-like conditions"
        description: ""
      - section: "MEA 2.6"
        title: "Safety metrics"
        description: "he AI system to be deployed is demonstrated to be safe, its residual negative risk does not exceed the risk tolerance, and can fail safely, particularly if made to operate beyond its knowledge limits. Safety metrics implicate system reliability and robustness, real-time monitoring, and response times for AI system failures."
      - section: "MEA 2.7"
        title: "AI system security and resilience"
        description: "These factors are evaluated and documented."
      - section: "MEA 2.8"
        title: "Transparency and accountability risks"
        description: "These risks are examined and documented."
      - section: "MEA 2.9"
        title: "Interpretability"
        description: "AI model is explained, validated, and documented. System output is interpreted within its context."
      - section: "MEA 2.10"
        title: "Privacy risks"
        description: "Privacy risk is examined and documented."
      - section: "MEA 2.11"
        title: "Fairness and bias risks"
        description: "These are evaluated and results are documented."
      - section: "MEA 2.12"
        title: "Sustainability risks"
        description: "Environmental impact of training and management are assessed and documented."


  - name: "EU AI ACT High Risk Providers"
    type: "Law"
    sections:
      - section: "Article 9"
        title: "Risk management system"
        description: "Identify risks associated with the system's intended use, specifically for health, safety, and fundamental rights. Assess impacts, test risk management strategies."
      - section: "Article 10"
        title: "Data management system"
        description: "Test datasets for potential biases, ensure datasets are relevant, representative, and data governance is set up."
      - section: "Article 17"
        title: "Quality management system"
        description: "Create and document a holistic process to ensure regulation compliance. This includes testing before, during, and after deployment."

  - name: "EU AI ACT GPAI with systemic risk"
    type: "Law"
    sections:
      - section: "Article 55.1a"
        title: "Model Evaluation and Adversarial Testing"
        description: "Conduct and document adversarial testing to identify and mitigate systemic risks."
      - section: "Article 55.1b"
        title: "Systemic Risk Mitigation"
        description: "Identify sources of risk and document mitigation strategies."