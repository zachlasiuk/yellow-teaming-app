# Pre-Deployment Testing

## Overview
Testing before deployment is critical to avoid all sorts of issues. Each team will test their systems based on their end goals, but some common themes exist to test to ensure best practice:

- **Model Accuracy:** Test and document model accuracy.
- **Scalability and Resilience:** Ensure your system can scale to your expected load and withstand unexpected adverse events when necessary.
- **Edge Cases:** Evaluate how well your system handles blank inputs, out-of-scope requests, and other edge-case situations.
- **Safety and Security:** Perform red teaming exercises to test how bad actors could break your system and mitigate against them.
- **Transparency and Accountability:** Test how users can seek redress for incorrect or problematic AI system outcomes.
- **Interpretability and Explainability:** Ensure you and your customers know how to interpret system output.
- **Privacy:** Validate that your customers' data privacy is maintained as expected.
- **Fairness and Bias:** Test model behavior across demographics and ensure outputs do not disproportionately harm certain groups.
- **Sustainability:** Assess and document the environmental impact of model training and inference during deployment.

